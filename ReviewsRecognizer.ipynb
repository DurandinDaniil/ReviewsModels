{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, Embedding, Dropout,SpatialDropout1D, Bidirectional\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import re\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(columns = ['text', 'rating', 'label'])\n",
    "df_tets = pd.DataFrame(columns = ['text', 'rating', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(purpose):\n",
    "    df = pd.DataFrame(columns = ['text', 'rating', 'label'])\n",
    "    for pos_neg in ['pos', 'neg']:\n",
    "        path = 'C:/Users/duran/Downloads/aclImdb' + '/{}/{}'.format(purpose, pos_neg)\n",
    "        label = 1 if pos_neg == 'pos' else 0\n",
    "        for file in os.listdir(path):\n",
    "            with open(os.path.join(path,file)) as f:\n",
    "                try:\n",
    "                    text = f.read()\n",
    "                except UnicodeDecodeError:\n",
    "                    continue\n",
    "                    \n",
    "                rating = file.split('_')[1].split('.')[0]\n",
    "                df = df.append({'text': text, 'rating': rating, 'label' :label}, ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = read_data('train')\n",
    "df_test = read_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.567e+03, 5.714e+03, 6.679e+03, 3.463e+03, 2.122e+03, 1.522e+03,\n",
       "        1.015e+03, 7.230e+02, 5.770e+02, 3.940e+02, 3.010e+02, 2.160e+02,\n",
       "        2.030e+02, 1.220e+02, 1.100e+02, 9.900e+01, 1.000e+02, 3.900e+01,\n",
       "        7.000e+00, 3.000e+00, 5.000e+00, 2.000e+00, 2.000e+00, 2.000e+00,\n",
       "        0.000e+00, 1.000e+00, 1.000e+00, 2.000e+00, 0.000e+00, 0.000e+00,\n",
       "        2.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
       "        0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00]),\n",
       " array([   52. ,   393.3,   734.6,  1075.9,  1417.2,  1758.5,  2099.8,\n",
       "         2441.1,  2782.4,  3123.7,  3465. ,  3806.3,  4147.6,  4488.9,\n",
       "         4830.2,  5171.5,  5512.8,  5854.1,  6195.4,  6536.7,  6878. ,\n",
       "         7219.3,  7560.6,  7901.9,  8243.2,  8584.5,  8925.8,  9267.1,\n",
       "         9608.4,  9949.7, 10291. , 10632.3, 10973.6, 11314.9, 11656.2,\n",
       "        11997.5, 12338.8, 12680.1, 13021.4, 13362.7, 13704. ]),\n",
       " <a list of 40 Patch objects>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = []\n",
    "for _, row in df_train.iterrows():\n",
    "    lengths.append(len(row['text']))\n",
    "plt.hist(lengths, bins = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\duran\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "def text_preprocessing(df):\n",
    "    df_preprocessed = df.copy()\n",
    "    corpus = []\n",
    "    for _, row in df.iterrows():\n",
    "        review = re.sub('[^a-zA-Z]', ' ', row['text'])\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "        ps = PorterStemmer()\n",
    "        review = [ps(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "        review = ' '.join(review)\n",
    "        corpus.append(review)\n",
    "    df_preprocessed['text'] = corpus\n",
    "    return df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed = text_preprocessing(df_train)\n",
    "df_test_preprocessed = text_preprocessing(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed.to_csv('preprocessed_train.csv')\n",
    "df_test_preprocessed.to_csv('preprocessed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed = pd.read_csv('preprocessed_train.csv')\n",
    "df_test_preprocessed = pd.read_csv('preprocessed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train_preprocessed['text'].values, df_train_preprocessed[['rating','label']].values, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_rat = y_train[:,0]\n",
    "y_train_lab = y_train[:,1]\n",
    "\n",
    "y_test_rat = y_test[:,0]\n",
    "y_test_lab = y_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features = 5000, ngram_range = (1,2)).fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = cv.transform(X_train).toarray()\n",
    "X_test = cv.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8449689937987598"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test,  y_test_lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(5000,))\n",
    "x = Dense(256)(inp)\n",
    "out = Dense(1, activation= 'linear')(x)\n",
    "model = Model(inputs=[inp], outputs=out)\n",
    "model.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17995 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "17995/17995 [==============================] - 1s 46us/sample - loss: 13.1811 - mae: 2.8162 - val_loss: 9.9104 - val_mae: 2.4595\n",
      "Epoch 2/10\n",
      "17995/17995 [==============================] - 1s 37us/sample - loss: 7.7180 - mae: 2.2102 - val_loss: 8.8066 - val_mae: 2.3298\n",
      "Epoch 3/10\n",
      "17995/17995 [==============================] - 1s 36us/sample - loss: 6.3404 - mae: 2.0187 - val_loss: 8.0343 - val_mae: 2.2379\n",
      "Epoch 4/10\n",
      "17995/17995 [==============================] - 1s 36us/sample - loss: 5.9541 - mae: 1.9464 - val_loss: 7.7723 - val_mae: 2.2290\n",
      "Epoch 5/10\n",
      "17995/17995 [==============================] - 1s 35us/sample - loss: 5.6200 - mae: 1.8915 - val_loss: 7.8442 - val_mae: 2.2392\n",
      "Epoch 6/10\n",
      "17995/17995 [==============================] - 1s 36us/sample - loss: 5.2117 - mae: 1.8408 - val_loss: 7.5052 - val_mae: 2.2012\n",
      "Epoch 7/10\n",
      "17995/17995 [==============================] - 1s 37us/sample - loss: 4.9892 - mae: 1.8134 - val_loss: 7.4939 - val_mae: 2.2086\n",
      "Epoch 8/10\n",
      "17995/17995 [==============================] - 1s 35us/sample - loss: 5.0451 - mae: 1.8080 - val_loss: 7.5157 - val_mae: 2.2095\n",
      "Epoch 9/10\n",
      "17995/17995 [==============================] - 1s 36us/sample - loss: 4.8441 - mae: 1.7874 - val_loss: 7.4618 - val_mae: 2.1961\n",
      "Epoch 10/10\n",
      "17995/17995 [==============================] - 1s 36us/sample - loss: 4.7361 - mae: 1.7702 - val_loss: 7.6112 - val_mae: 2.2160\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, y_train_rat, validation_split=0.1, epochs=10, batch_size=128, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8249649929985997\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(preds)):\n",
    "    if preds[i] < 5 and y_test[:,1][i] == 0:\n",
    "        count+=1\n",
    "    if preds[i] > 5 and y_test[:,1][i] == 1:\n",
    "        count+=1\n",
    "print(count/len(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imdb.vocab') as f:\n",
    "    vocab = f.read().split('\\n')\n",
    "    \n",
    "vocab = dict(zip(vocab, [*range(1,len(vocab)+1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = {}\n",
    "with open(\"glove.6B.100d.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing_for_word2vec(df):\n",
    "    df_preprocessed = df.copy()\n",
    "    corpus = []\n",
    "    for _, row in df.iterrows():\n",
    "        review = re.sub('[^a-zA-Z]', ' ', row['text'])\n",
    "        review = review.lower()\n",
    "        review = [word for word in review if not word in set(stopwords.words('english'))]\n",
    "        corpus.append(review)\n",
    "    df_preprocessed['text'] = corpus\n",
    "    return df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed = text_preprocessing_for_word2vec(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed.to_csv('pre_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed = pd.read_csv('pre_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed['text'] = df_train_preprocessed.apply(lambda row: row['text'].split(' '), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train_preprocessed['text'].values, df_train_preprocessed[['rating','label']].values, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [[vocab.get(wrd, 0) for wrd in comment] for comment in X_train]\n",
    "test_sequences = [[vocab.get(wrd, 0)  for wrd in comment] \n",
    "                  for comment in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(sequences, maxlen=seq_len, \n",
    "                     padding=\"pre\", truncating=\"post\")\n",
    "\n",
    "X_test = pad_sequences(test_sequences, maxlen=seq_len, \n",
    "                     padding=\"pre\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "vm_dim = 100\n",
    "nb_words = len(vocab)\n",
    "wv_matrix = np.zeros((nb_words, vm_dim))\n",
    "for word, i in vocab.items():\n",
    "    try:\n",
    "        wv_matrix[i] = embeddings_dict[word]\n",
    "    except:\n",
    "        pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_layer = Embedding(nb_words,\n",
    "                     vm_dim,\n",
    "                     mask_zero=False,\n",
    "                     weights=[wv_matrix],\n",
    "                     input_length=seq_len,\n",
    "                     trainable=True)\n",
    "\n",
    "comment_input = Input(shape=(seq_len,), dtype='int32')\n",
    "embedded_sequences = wv_layer(comment_input)\n",
    "\n",
    "embedded_sequences = SpatialDropout1D(0.2)(embedded_sequences)\n",
    "x = Bidirectional(LSTM(64, return_sequences=False))(embedded_sequences)\n",
    "x = Dropout(0.2)(x)\n",
    "preds = Dense(1, activation='linear')(x)\n",
    "\n",
    "model_nn = Model(inputs=[comment_input], outputs=preds)\n",
    "model_nn.compile(loss='mse',\n",
    "              optimizer='adam',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17995 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "17995/17995 [==============================] - 12s 692us/sample - loss: 13.6242 - mae: 3.3317 - val_loss: 11.9562 - val_mae: 3.2440\n",
      "Epoch 2/10\n",
      "17995/17995 [==============================] - 10s 579us/sample - loss: 10.8051 - mae: 2.9488 - val_loss: 9.5320 - val_mae: 2.7515\n",
      "Epoch 3/10\n",
      "17995/17995 [==============================] - 10s 575us/sample - loss: 9.6753 - mae: 2.6907 - val_loss: 7.0588 - val_mae: 2.1906\n",
      "Epoch 4/10\n",
      "17995/17995 [==============================] - 11s 589us/sample - loss: 6.0376 - mae: 1.9317 - val_loss: 6.0646 - val_mae: 1.9574\n",
      "Epoch 5/10\n",
      "17995/17995 [==============================] - 10s 582us/sample - loss: 4.2895 - mae: 1.5685 - val_loss: 4.8099 - val_mae: 1.6539\n",
      "Epoch 6/10\n",
      "17995/17995 [==============================] - 11s 587us/sample - loss: 3.3522 - mae: 1.3747 - val_loss: 4.7269 - val_mae: 1.5995\n",
      "Epoch 7/10\n",
      "17995/17995 [==============================] - 10s 577us/sample - loss: 2.6629 - mae: 1.2205 - val_loss: 4.8847 - val_mae: 1.6033\n",
      "Epoch 8/10\n",
      "17995/17995 [==============================] - 11s 586us/sample - loss: 2.2056 - mae: 1.1186 - val_loss: 5.0120 - val_mae: 1.6124\n",
      "Epoch 9/10\n",
      "17995/17995 [==============================] - 10s 575us/sample - loss: 1.8955 - mae: 1.0433 - val_loss: 5.1543 - val_mae: 1.6305\n",
      "Epoch 10/10\n",
      "17995/17995 [==============================] - 11s 588us/sample - loss: 1.6627 - mae: 0.9805 - val_loss: 5.2205 - val_mae: 1.6285\n"
     ]
    }
   ],
   "source": [
    "hist = model_nn.fit(X_train, y_train_rat, validation_split=0.1, epochs=10, batch_size=128, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8449689937987598\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(len(preds)):\n",
    "    if preds[i] < 5 and y_test[:,1][i] == 0:\n",
    "        count+=1\n",
    "    if preds[i] > 5 and y_test[:,1][i] == 1:\n",
    "        count+=1\n",
    "print(count/len(preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
